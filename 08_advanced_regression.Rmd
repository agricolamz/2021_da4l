---
editor_options: 
  chunk_output_type: console
---

# (PART) Продвинутый регрессионный анализ {-}

# Ограничения на применение регрессии

Некоторые думают, что линейная регрессия решит все их проблемы (по крайней мере те из них, которые связаны с предсказанием какой-то числовой переменной). Это так. Но нужно быть осторожным --- у регрессии есть свои ограничения на применение.

## Введение

[Ссылка](https://raw.githubusercontent.com/agricolamz/2021_da4l/master/data/linear_regression_intro.Rmd) на RMD с обсуждением.

### Библиотеки
```{r, message=FALSE, warning=FALSE}
library(tidyverse)
```

### Lexical Decision Task data
Dataset and description from [Rling package by Natalia Levshina](https://benjamins.com/sites/z.195/content/package.html). This data set contains 100 randomly selected words from the English Lexicon Project data (Balota et al. 2007), their lengths, mean reaction times and corpus frequencies.

```{r, message=FALSE, warning=FALSE}
ldt <- read_csv("https://goo.gl/ToxfU6")
ldt
```

## Нелинейность взаимосвязи
Давайте посмотрим на простой график:

```{r}
ldt %>% 
  ggplot(aes(Mean_RT, Freq))+
  geom_point()+
  theme_bw()
```

Регрессия на таких данных будет супер неиформативна:

```{r}
ldt %>% 
  ggplot(aes(Mean_RT, Freq))+
  geom_point()+
  geom_smooth(method = "lm")+
  theme_bw()

m1 <- summary(lm(Mean_RT~Freq, data = ldt))
m1
```

### Логарифмирование

```{r}
ldt %>% 
  ggplot(aes(Mean_RT, log(Freq)))+
  geom_point()+
  geom_smooth(method = "lm")+
  theme_bw()

ldt %>% 
  ggplot(aes(Mean_RT, log(Freq+1)))+
  geom_point()+
  geom_smooth(method = "lm")+
  theme_bw()

m2 <- summary(lm(Mean_RT~log(Freq+1), data = ldt))
m2
m1$adj.r.squared
m2$adj.r.squared
```

Отлогорифмировать можно и другую переменную.
```{r}
ldt %>% 
  ggplot(aes(log(Mean_RT), log(Freq  + 1)))+
  geom_point()+
  geom_smooth(method = "lm")+
  theme_bw()

m3 <- summary(lm(log(Mean_RT)~log(Freq+1), data = ldt))
m1$adj.r.squared
m2$adj.r.squared
m3$adj.r.squared
```

Как интерпретировать полученную регрессию с двумя отлогорифмированными значениями?

В обычной линейной регресии мы узнаем отношения между $x$ и  $y$:
$$y_i = \beta_0+\beta_1\times x_i$$

Как изменится $y_j$, если мы увеличем $x_i + 1 = x_j$?
$$y_j = \beta_0+\beta_1\times x_j$$

$$y_j - y_i = \beta_0+\beta_1\times x_j - (\beta_0+\beta_1\times x_i)  = \beta_1(x_j - x_i)$$

Т. е. $y$ увеличится на $\beta_1$ , если $x$ увеличится на 1. Что же будет с логарифмированными переменными? Как изменится $y_j$, если мы увеличем $x_i + 1 = x_j$?

$$\log(y_j) - \log(y_i) = \beta_1\times (\log(x_j) - \log(x_i))$$

$$\log\left(\frac{y_j}{y_i}\right) = \beta_1\times \log\left(\frac{x_j}{x_i}\right) = \log\left(\left(\frac{x_j}{x_i}\right) ^ {\beta_1}\right)$$

$$\frac{y_j}{y_i}= \left(\frac{x_j}{x_i}\right) ^ {\beta_1}$$

Т. е. $y$ увеличится на $\beta_1$ процентов, если $x$ увеличится на 1 процент.

Логарифмирование --- не единственный вид траснформации:

* трансформация Тьюки
```{r, eval = FALSE}
shiny::runGitHub("agricolamz/tukey_transform")
```

```{r, echo= FALSE}
data.frame(cors = c(sapply(seq(-5, -0.01, 0.01), function(i){
  abs(cor(ldt$Mean_RT, -(ldt$Freq+1)^i))
}),
abs(cor(ldt$Mean_RT, log(ldt$Freq+1))),
sapply(seq(0.01, 5, 0.01), function(i){
  abs(cor(ldt$Mean_RT, (ldt$Freq+1)^i))
})),
bandwidth = seq(-5, 5, 0.01)) %>%
  ggplot(aes(bandwidth, cors))+
  geom_line()+
  theme_bw()+
  geom_vline(xintercept = 0.1, linetype = 2)+
  labs(y = "correlation",
       title = "average reaction time ~ Tukey transformed word frequencies")
```

* трансформация Бокса — Кокса
* ...

```{block, type = "rmdtask"}
В [датасет](https://raw.githubusercontent.com/agricolamz/2021_da4l/master/data/freq_dict_2009.csv) собрана частотность разных лемм на основании корпуса НКРЯ [@lyashevskaya09] (в датасете только значения больше ipm > 10). Известно, что частотность слова связана с рангом слова (см. закон Ципфа). Постройте переменную ранга и визуализируйте связь ранга и логорифма частотности с разбивкой по частям речи. Какие части речи так и не приобрели после трансформации "приемлимую" линейную форму? (я насчитал 5 таких)
```

```{r, include=FALSE}
df <- read_tsv("data/freq_dict_2009.csv")
df %>%
  group_by(pos) %>% 
  mutate(id = 1:n()) %>% 
  ggplot(aes(id, log(freq_ipm)))+
  geom_point()+
  facet_wrap(~pos, scale = "free")
```


```{r, results='asis', echo=FALSE}
library(checkdown)
check_question(answer = c("a", "adv", "s", "s.PROP", "v"), options = sort(unique(df$pos)), type = "checkbox")
```

## Нормальность распределение остатков

Линейная регрессия предполагает нормальность распределения остатков. Когда связь не линейна, то остатки тоже будут распределены не нормально.

Можно смотреть на певрый график используя функцию `plot(m1)` --- график остатков. Интерпретаций этого графика достаточно много (см. [статью про это](http://docs.statwing.com/interpreting-residual-plots-to-improve-your-regression/)).

Можно смотреть на qqplot:

```{r, message=FALSE}
tibble(res = m1$residuals) %>% 
  ggplot(aes(res))+
  geom_histogram(aes(y = ..density..))+
  stat_function(fun = dnorm, args = list(mean = 0, sd = sd(m1$residuals)), color = "red")

qqnorm(m1$residuals)
qqline(m1$residuals)

tibble(res = m2$residuals) %>% 
  ggplot(aes(res))+
  geom_histogram(aes(y = ..density..))+
  stat_function(fun = dnorm, args = list(mean = 0, sd = sd(m2$residuals)), color = "red")
qqnorm(m2$residuals)
qqline(m2$residuals)

tibble(res = m3$residuals) %>% 
  ggplot(aes(res))+
  geom_histogram(aes(y = ..density..))+
  stat_function(fun = dnorm, args = list(mean = 0, sd = sd(m3$residuals)), color = "red")
qqnorm(m3$residuals)
qqline(m3$residuals)
```

## Гетероскидастичность
Распределение остатков непостоянно (т. е. не гомоскидастичны):
```{r}
ldt %>% 
  ggplot(aes(Mean_RT, Freq))+
  geom_point()+
  theme_bw()
```

Тоже решается преобазованием данных.



## Мультиколлинеарность
Линейная связь между некоторыми предикторами в модели.

* корреляционная матрица
* VIF (Variance inflation factor), `car::vif()`
  * VIF = 1 (Not correlated)
  * 1 < VIF < 5 (Moderately correlated)
  * VIF >=5 (Highly correlated)

## Независимость наблюдений
Наблюдения должны быть независимы. В ином случае нужно использовать модель со смешанными эффектами.

### Линейная модель со смешанными эффектами

Если в данных есть некоторая группировка, тогда 


```{r}
library(lme4)
library(lmerTest)
library(ggfortify)
```

