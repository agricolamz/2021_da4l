---
editor_options: 
  chunk_output_type: console
---

```{r, include=FALSE}
library(tidyverse)
theme_set(theme_bw())
```


# Логистическая, порядковая и мультиномиальная регрессия

```{r}
library(tidyverse)
```

Логистическая (logit, logistic) и мультиномиальная (multinomial) регрессия применяются в случаях, когда зависимая переменная является категориальной:

* с двумя значениями (логистическая регрессия)
* с более чем двумя значениями, упорядоченными в иерархию (порядковая регрессия)
* с более чем двумя значениями (мультиномиальная регрессия)

## Логистическая регрессия
### Теория
Мы хотим чего-то такого:
$$\underbrace{y}_{[-\infty, +\infty]}=\underbrace{\mbox{β}_0+\mbox{β}_1\cdot x_1+\mbox{β}_2\cdot x_2 + \dots +\mbox{β}_k\cdot x_k +\mbox{ε}_i}_{[-\infty, +\infty]}$$
Вероятность — отношение количества успехов к общему числу событий:
$$p = \frac{\mbox{# успехов}}{\mbox{# неудач} + \mbox{# успехов}}, p \in [0, 1]$$
Шансы — отношение количества успехов к количеству неудач:
$$odds = \frac{p}{1-p} = \frac{p\mbox{(успеха)}}{p\mbox{(неудачи)}}, odds \in [0, +\infty]$$
Натуральный логарифм шансов:
$$\log(odds) \in [-\infty, +\infty]$$

Но, что нам говорит логарифм шансов? Как нам его интерпретировать?

```{r}
tibble(n = 10,
           success = 1:9,
           failure = n - success,
           prob.1 = success/(success+failure),
           odds = success/failure,
           log_odds = log(odds),
           prob.2 = exp(log_odds)/(1+exp(log_odds)))
```

Как связаны вероятность и логарифм шансов:
$$\log(odds) = \log\left(\frac{p}{1-p}\right)$$
$$p = \frac{\exp(\log(odds))}{1+\exp(\log(odds))}$$

```{block, type = "rmdtask"}
Логарифм шансов равен 0.25. Посчитайте вероятность успеха:
```

```{r, results='asis', echo = FALSE}
library(checkdown)
log_odds <- 5/20
check_question(answer = exp(log_odds)/(1+exp(log_odds)))
```

Как связаны вероятность и логарифм шансов:

```{r, echo=FALSE}
tibble(p = seq(0, 1, 0.001),
       log_odds = log(p/(1-p))) %>% 
  ggplot(aes(log_odds, p))+
  geom_line()+
  labs(x = latex2exp::TeX("$\\log\\left(\\frac{p}{1-p}\\right)$"))

tibble(p = seq(0, 1, 0.001),
       log_odds = log(p/(1-p))+2) %>% 
  ggplot(aes(log_odds, p))+
  geom_line()+
  labs(x = latex2exp::TeX("$\\log\\left(\\frac{p}{1-p}\\right)+2$"))

tibble(p = seq(0, 1, 0.001),
       log_odds = 2*log(p/(1-p))) %>% 
  ggplot(aes(log_odds, p))+
  geom_line()+
  labs(x = latex2exp::TeX("$2\\times\\log\\left(\\frac{p}{1-p}\\right)$"))

tibble(p = seq(0, 1, 0.001),
       log_odds = -2*log(p/(1-p))) %>% 
  ggplot(aes(log_odds, p))+
  geom_line()+
  labs(x = latex2exp::TeX("$-2\\times\\log\\left(\\frac{p}{1-p}\\right)$"))
```

### Практика

В датасет собрано 19 языков, со следующими переменными:

* `language` --- переменная, содержащая язык
* `tone` --- бинарная переменная, обозначающая наличие тонов
* `long_vowels` --- бинарная переменная, обозначающая наличие долгих гласных
* `stress` --- бинарная переменная, обозначающая наличие ударения
* `ejectives` --- бинарная переменная, обозначающая наличие абруптивных
* `consonants` --- переменная, содержащая информацию о количестве согласных
* `vowels` --- переменная, содержащая информацию о количестве гласных

```{r, message = FALSE}
phonological_profiles <- read_csv("https://raw.githubusercontent.com/agricolamz/2021_da4l/master/data/phonological_profiles.csv")
glimpse(phonological_profiles)
set.seed(42)
phonological_profiles %>% 
  ggplot(aes(ejectives, consonants))+
  geom_boxplot(aes(fill = ejectives), show.legend = FALSE, outlier.alpha = 0)+ 
  # по умолчанию боксплот рисует выбросы, outlier.alpha = 0 -- это отключает
  geom_jitter(size = 3)
```

#### Почему не линейную регрессию?

```{r}
lm_0 <- lm(as.double(ejectives)~1, data = phonological_profiles)
lm_1 <- lm(as.double(ejectives)~consonants, data = phonological_profiles)
lm_0
lm_1
```
Первая модель:
$$ejectives = 0.3158 \times consonants$$
Вторая модель:
$$ejectives = -0.5389 + 0.0353 \times consonants$$

```{r, message=FALSE}
phonological_profiles %>% 
  ggplot(aes(consonants, as.double(ejectives)))+
  geom_point()+
  geom_smooth(method = "lm")+
  theme_bw()+
  labs(y = "ejectives (yes = 2, no = 1)")
```

#### Модель без предиктора

```{r}
logit_0 <- glm(ejectives~1, family = "binomial", data = phonological_profiles)
summary(logit_0)
logit_0$coefficients
table(phonological_profiles$ejectives)
log(6/13) # β0
6/(13+6) # p
exp(log(6/13))/(1+exp(log(6/13))) # p
```

```{block, type = "rmdtask"}
Какой коэфициент логистической регрессии, мы получим, запустив модель, предсказывающую количество *s*-генитивов, если наши данные состоят из 620 *s*-генитивов из 699 генетивных контекстов?

Ответ округлите до трех и меньше знаков после запятой.
```

```{r, echo=FALSE, results='asis'}
check_question(round(log(620/(699-620)), 3))
```

#### Модель c одним числовым предиктором
```{r, message=FALSE}
logit_1 <- glm(ejectives~consonants, family = "binomial", data = phonological_profiles)
summary(logit_1)
logit_1$coefficients

phonological_profiles %>% 
  mutate(ejectives = as.double(ejectives)) %>% 
  ggplot(aes(consonants, ejectives)) +
  geom_smooth(method = "glm", 
              method.args = list(family = "binomial"),
              se = FALSE)+
  geom_point()
```

Какова вероятность, что в языке с 29 согласными есть абруптивные?
```{r}
logit_1$coefficients
```

$$\log\left({\frac{p}{1-p}}\right)_i=\beta_0+\beta_1\times consinants_i + \epsilon_i$$
$$\log\left({\frac{p}{1-p}}\right)=-12.1123347 + 0.4576095 \times 29 = 1.158341$$
$$p = \frac{e^{1.158341}}{1+e^{1.158341}} = 0.7610311$$

```{r}
# log(odds)
predict(logit_1, newdata = data.frame(consonants = 29))
# p
predict(logit_1, newdata = data.frame(consonants = 29), type = "response")
```

```{block, type = "rmdtask"}
Какой логорифм шансов предсказывает наша модель для языка с 25 согласными (6 знаков после запятой)?
```

```{r, results='asis', echo = FALSE}
check_question(round(predict(logit_1, newdata = data.frame(consonants = 25)), 6))
```

```{block, type = "rmdtask"}
Какую вероятность предсказывает наша модель для языка с 25 согласными (6 знаков после запятой)?
```
```{r, results='asis', echo = FALSE}
check_question(round(predict(logit_1, newdata = data.frame(consonants = 25), type = "response"), 6))
```

#### Модель c одним категориальным предиктором
```{r}
logit_2 <- glm(ejectives~area, family = "binomial", data = phonological_profiles)
summary(logit_2)
logit_2$coefficients
table(phonological_profiles$ejectives, phonological_profiles$area)
log(1/6) # Eurasia
log(3/1) # North America
```

#### Множественная регрессия
```{r}
logit_3 <- glm(ejectives~consonants+area, family = "binomial", data = phonological_profiles)
summary(logit_3)
```

#### Cравнение моделей

```{r}
AIC(logit_0, logit_1, logit_2, logit_3)
BIC(logit_0, logit_1, logit_2, logit_3)
```

```{block, type = "rmdtask"}
Выберите наилучшую модель согласно AIC и BIC:
```

```{r, results='asis', echo = FALSE}
check_question("logit_1", options = paste0("logit_", 0:3), alignment = TRUE, type = "radio")
```

Для того, чтобы интерпретировать коэффициенты нужно проделать трансформацию:
```{r}
(exp(logit_1$coefficients)-1)*100
```
Перед нами процентное изменние шансов при увеличении независимой переменной на 1.

Было предложено много аналогов R$^2$, например, McFadden's R squared:
```{r}
pscl::pR2(logit_1)
```

```{block, type = "rmdtask"}
Проанализируйте в датасете с языками связь количества сегментов и наличия ударения. Постройте регрессию, визуализируйте связь. Какой вывод вы можете сделать?
```

```{r, include=FALSE}
phonological_profiles %>% 
  mutate(phonemes = consonants+vowels) %>% 
  glm(stress~phonemes, family = "binomial", data = .) ->
  logit_new
summary(logit_new)
logit_new$coefficients

phonological_profiles %>% 
  mutate(phonemes = consonants+vowels,
         stress = as.double(stress)) %>% 
  ggplot(aes(phonemes, stress)) +
  geom_smooth(method = "glm", 
              method.args = list(family = "binomial"),
              se = FALSE)+
  geom_point()
```


## Порядковая логистическая регрессия

Данные взяты из [исследования [Endresen, Janda 2015]](https://goo.gl/GC4RjQ), посвященное исследованию маргинальных глаголов изменения состояния в русском языке. Испытуемые (70 школьников, 51 взрослый) оценивали по [шкале Ликерта (1...5)](https://goo.gl/R4gHiq) приемлемость глаголов с приставками _о-_ и _у-_:

* широко используемуе в СРЛЯ (_освежить_, _уточнить_)
* встретившие всего несколько раз в корпусе (_оржавить_, _увкуснить_)
* искусственные слова (_ономить_, _укампить_)

```{r, message=FALSE}
marginal_verbs <- read_csv("https://raw.githubusercontent.com/agricolamz/2021_da4l/master/data/marginal_verbs.csv")
head(marginal_verbs)
```

Переменные в датасете:

* Gender
* Age
* AgeGroup — взрослые или школьники
* Education
* City
* SubjectCode — код испытуемого
* Score — оценка, поставленная испытуемым (A — самая высокая, E  — самая низкая)
* GivenScore — оценка, поставленная испытуемым (5 — самая высокая, 1  — самая низкая)
* Stimulus
* Prefix
* WordType — тип слова: частотное, редкое, искусственное
* CorpusFrequency — частотность в корпусе

```{r}
marginal_verbs$Score <- factor(marginal_verbs$Score)
levels(marginal_verbs$Score)
ordinal <- MASS::polr(Score~Prefix+WordType+CorpusFrequency, data = marginal_verbs)
summary(ordinal)
ordinal$coefficients
```

Как и раньше, можно преобразовать коэффициенты:
```{r}
(exp(ordinal$coefficients)-1)*100
```

$$\log(\frac{p(A)}{p(B|C|D|E)}) = -2.6275 + 0.136619412 \times Prefixu +$$
$$+ 1.340602696 \times WordTypenonce -$$    
$$-4.655327418 \times WordTypestandard - $$
$$ - 0.001014583\times CorpusFrequency$$
$$\log(\frac{p(A|B)}{p(C|D|E)}) = -1.4531 + 0.136619412 \times Prefixu + $$
$$ + 1.340602696 \times WordTypenonce-$$
$$-4.655327418 \times WordTypestandard -$$
$$ -0.001014583\times CorpusFrequency$$
$$\log(\frac{p(A|B|C)}{p(D|E)}) = -0.2340 + 0.136619412 \times Prefixu + $$
$$ + 1.340602696 \times WordTypenonce-$$
$$-4.655327418 \times WordTypestandard - $$
$$-0.001014583\times CorpusFrequency$$

$$\log(\frac{p(A|B|C|D)}{p(E)}) = 0.7324 + 0.136619412 \times Prefixu +$$
$$ + 1.340602696 \times WordTypenonce-$$
$$-4.655327418 \times WordTypestandard -$$
$$=0.001014583\times CorpusFrequency$$

```{r}
head(predict(ordinal))
head(predict(ordinal, type = "probs"))
marginal_verbs %>%
  bind_cols(as_tibble(predict(ordinal, type = "probs"))) %>% 
  gather(score, predictions, A:E) %>% 
  ggplot(aes(x = score, y = predictions, fill = score)) +
  geom_col(position = "dodge")+
  facet_grid(Prefix~WordType)
```

```{r}
library(ggeffects)
ordinal %>% 
  ggpredict(terms = c("Prefix", "WordType")) %>% 
  plot()
```

## Мультиномиальная регрессия

В этом датасете представлены три нанайских гласных  i, ɪ и e, произнесенные нанайским носителем мужского пола из селения Джуен. Каждая строчка --- отдельное произнесение. Переменные:

* f1 --- первая форманта
* f2 --- вторая форманта

```{r}
nanai <- read_csv("https://raw.githubusercontent.com/agricolamz/2021_da4l/master/data/nanai_vowels.csv")
nanai %>% 
  ggplot(aes(f2, f1, label = sound, color = sound))+
  geom_text()+
  geom_rug()+
  scale_y_reverse()+
  scale_x_reverse()+
  stat_ellipse()+
  theme_bw()+
  theme(legend.position = "none")+
  labs(title = "Нанайские гласные в произнесении мужчины из селения Джуен")
```

```{r}
mult <- nnet::multinom(sound~f1+f2, data = nanai)
mult
```

$$\log(\frac{p(e)}{p(ɪ)}) = -41.46147 + 0.02360077\times f1 +0.01937067\times f2$$
$$\log(\frac{p(i)}{p(ɪ)}) = -22.85202 -0.04263175\times f1 +  0.02315226\times f2$$

```{r, warning=FALSE}
nanai %>% 
  mutate(prediction = predict(mult),
         correctness = sound == prediction) %>% 
  ggplot(aes(f1, f2, label = sound, color = correctness))+
  geom_text(aes(size = !correctness), show.legend = FALSE)+
  scale_y_reverse()+
  scale_x_reverse()+
  theme_bw()+
  labs(title = "Нанайские гласные в произнесении мужчины из селения Джуен",
       subtitle = "мультиномиальная регрессия")
```

