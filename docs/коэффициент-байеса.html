<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>7 Коэффициент Байеса | Анализ данных для лингвистов</title>
  <meta name="description" content="7 Коэффициент Байеса | Анализ данных для лингвистов" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="7 Коэффициент Байеса | Анализ данных для лингвистов" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="7 Коэффициент Байеса | Анализ данных для лингвистов" />
  
  
  

<meta name="author" content="Г. А. Мороз" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="байесовский-доверительный-интервал.html"/>
<link rel="next" href="ссылки-на-литературу.html"/>
<script src="libs/header-attrs-2.6/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="libs/pagedtable-1.1/js/pagedtable.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Анализ данных для лингвистов</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> О курсе</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#домашние-задания"><i class="fa fa-check"></i><b>1.1</b> Домашние задания</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#используемые-пакеты"><i class="fa fa-check"></i><b>1.2</b> Используемые пакеты</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="распределения.html"><a href="распределения.html"><i class="fa fa-check"></i><b>2</b> Распределения</a>
<ul>
<li class="chapter" data-level="2.1" data-path="распределения.html"><a href="распределения.html#распределения-в-r"><i class="fa fa-check"></i><b>2.1</b> Распределения в R</a></li>
<li class="chapter" data-level="2.2" data-path="распределения.html"><a href="распределения.html#дискретные-переменные"><i class="fa fa-check"></i><b>2.2</b> Дискретные переменные</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="распределения.html"><a href="распределения.html#биномиальное-распределение"><i class="fa fa-check"></i><b>2.2.1</b> Биномиальное распределение</a></li>
<li class="chapter" data-level="2.2.2" data-path="распределения.html"><a href="распределения.html#геометрическое-распределение"><i class="fa fa-check"></i><b>2.2.2</b> Геометрическое распределение</a></li>
<li class="chapter" data-level="2.2.3" data-path="распределения.html"><a href="распределения.html#распределение-пуассона"><i class="fa fa-check"></i><b>2.2.3</b> Распределение Пуассона</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="распределения.html"><a href="распределения.html#числовые-переменные"><i class="fa fa-check"></i><b>2.3</b> Числовые переменные</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="распределения.html"><a href="распределения.html#нормальное-распределение"><i class="fa fa-check"></i><b>2.3.1</b> Нормальное распределение</a></li>
<li class="chapter" data-level="2.3.2" data-path="распределения.html"><a href="распределения.html#логнормальное-распределение"><i class="fa fa-check"></i><b>2.3.2</b> Логнормальное распределение</a></li>
<li class="chapter" data-level="2.3.3" data-path="распределения.html"><a href="распределения.html#что-еще-почитать-про-распределения"><i class="fa fa-check"></i><b>2.3.3</b> Что еще почитать про распределения?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="метод-максимального-правдоподобия.html"><a href="метод-максимального-правдоподобия.html"><i class="fa fa-check"></i><b>3</b> Метод максимального правдоподобия</a>
<ul>
<li class="chapter" data-level="3.1" data-path="метод-максимального-правдоподобия.html"><a href="метод-максимального-правдоподобия.html#оценка-вероятности"><i class="fa fa-check"></i><b>3.1</b> Оценка вероятности</a></li>
<li class="chapter" data-level="3.2" data-path="метод-максимального-правдоподобия.html"><a href="метод-максимального-правдоподобия.html#функция-правдоподобия"><i class="fa fa-check"></i><b>3.2</b> Функция правдоподобия</a></li>
<li class="chapter" data-level="3.3" data-path="метод-максимального-правдоподобия.html"><a href="метод-максимального-правдоподобия.html#пример-с-непрерывным-распределением"><i class="fa fa-check"></i><b>3.3</b> Пример с непрерывным распределением</a></li>
<li class="chapter" data-level="3.4" data-path="метод-максимального-правдоподобия.html"><a href="метод-максимального-правдоподобия.html#метод-максимального-правдоподобия-mle"><i class="fa fa-check"></i><b>3.4</b> Метод максимального правдоподобия (MLE)</a></li>
<li class="chapter" data-level="3.5" data-path="метод-максимального-правдоподобия.html"><a href="метод-максимального-правдоподобия.html#логорифм-функции-правдоподобия"><i class="fa fa-check"></i><b>3.5</b> Логорифм функции правдоподобия</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="модели-смеси-распределений.html"><a href="модели-смеси-распределений.html"><i class="fa fa-check"></i><b>4</b> Модели смеси распределений</a>
<ul>
<li class="chapter" data-level="4.1" data-path="модели-смеси-распределений.html"><a href="модели-смеси-распределений.html#cмеси-распределений"><i class="fa fa-check"></i><b>4.1</b> Cмеси распределений</a></li>
<li class="chapter" data-level="4.2" data-path="модели-смеси-распределений.html"><a href="модели-смеси-распределений.html#модели-смеси-распределений-1"><i class="fa fa-check"></i><b>4.2</b> Модели смеси распределений</a></li>
<li class="chapter" data-level="4.3" data-path="модели-смеси-распределений.html"><a href="модели-смеси-распределений.html#несколько-замечаний"><i class="fa fa-check"></i><b>4.3</b> Несколько замечаний</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="байесовский-статистический-вывод.html"><a href="байесовский-статистический-вывод.html"><i class="fa fa-check"></i><b>5</b> Байесовский статистический вывод</a>
<ul>
<li class="chapter" data-level="5.1" data-path="байесовский-статистический-вывод.html"><a href="байесовский-статистический-вывод.html#нотация"><i class="fa fa-check"></i><b>5.1</b> Нотация</a></li>
<li class="chapter" data-level="5.2" data-path="байесовский-статистический-вывод.html"><a href="байесовский-статистический-вывод.html#категориальный-пример"><i class="fa fa-check"></i><b>5.2</b> Категориальный пример</a></li>
<li class="chapter" data-level="5.3" data-path="байесовский-статистический-вывод.html"><a href="байесовский-статистический-вывод.html#разница-между-фриквентиским-и-байесовским-подходами"><i class="fa fa-check"></i><b>5.3</b> Разница между фриквентиским и байесовским подходами</a></li>
<li class="chapter" data-level="5.4" data-path="байесовский-статистический-вывод.html"><a href="байесовский-статистический-вывод.html#биномиальные-данные"><i class="fa fa-check"></i><b>5.4</b> Биномиальные данные</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="байесовский-статистический-вывод.html"><a href="байесовский-статистический-вывод.html#биномиальное-распределение-1"><i class="fa fa-check"></i><b>5.4.1</b> Биномиальное распределение</a></li>
<li class="chapter" data-level="5.4.2" data-path="байесовский-статистический-вывод.html"><a href="байесовский-статистический-вывод.html#бета-распределение"><i class="fa fa-check"></i><b>5.4.2</b> Бета распределение</a></li>
<li class="chapter" data-level="5.4.3" data-path="байесовский-статистический-вывод.html"><a href="байесовский-статистический-вывод.html#байесовский-апдейт-биномиальных-данных"><i class="fa fa-check"></i><b>5.4.3</b> Байесовский апдейт биномиальных данных</a></li>
<li class="chapter" data-level="5.4.4" data-path="байесовский-статистический-вывод.html"><a href="байесовский-статистический-вывод.html#байесовский-апдейт-биномиальных-данных-несколько-моделей"><i class="fa fa-check"></i><b>5.4.4</b> Байесовский апдейт биномиальных данных: несколько моделей</a></li>
<li class="chapter" data-level="5.4.5" data-path="байесовский-статистический-вывод.html"><a href="байесовский-статистический-вывод.html#что-почитать"><i class="fa fa-check"></i><b>5.4.5</b> Что почитать?</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="байесовский-статистический-вывод.html"><a href="байесовский-статистический-вывод.html#байесовский-апдейт-нормального-распределения"><i class="fa fa-check"></i><b>5.5</b> Байесовский апдейт нормального распределения</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="байесовский-статистический-вывод.html"><a href="байесовский-статистический-вывод.html#байесовский-апдейт-нормального-распределения-выбор-из-нескольких-моделей"><i class="fa fa-check"></i><b>5.5.1</b> Байесовский апдейт нормального распределения: выбор из нескольких моделей</a></li>
<li class="chapter" data-level="5.5.2" data-path="байесовский-статистический-вывод.html"><a href="байесовский-статистический-вывод.html#байесовский-апдейт-нормального-распределения-непрерывный-вариант"><i class="fa fa-check"></i><b>5.5.2</b> Байесовский апдейт нормального распределения: непрерывный вариант</a></li>
<li class="chapter" data-level="5.5.3" data-path="байесовский-статистический-вывод.html"><a href="байесовский-статистический-вывод.html#что-почитать-1"><i class="fa fa-check"></i><b>5.5.3</b> Что почитать?</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="байесовский-статистический-вывод.html"><a href="байесовский-статистический-вывод.html#другие-распределения"><i class="fa fa-check"></i><b>5.6</b> Другие распределения</a></li>
<li class="chapter" data-level="5.7" data-path="байесовский-статистический-вывод.html"><a href="байесовский-статистический-вывод.html#вопросы-к-апостериорному-распределению"><i class="fa fa-check"></i><b>5.7</b> Вопросы к апостериорному распределению</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="байесовский-доверительный-интервал.html"><a href="байесовский-доверительный-интервал.html"><i class="fa fa-check"></i><b>6</b> Байесовский доверительный интервал</a>
<ul>
<li class="chapter" data-level="6.1" data-path="байесовский-доверительный-интервал.html"><a href="байесовский-доверительный-интервал.html#фреквентисткий-доверительный-интервал"><i class="fa fa-check"></i><b>6.1</b> Фреквентисткий доверительный интервал</a></li>
<li class="chapter" data-level="6.2" data-path="байесовский-доверительный-интервал.html"><a href="байесовский-доверительный-интервал.html#байесовский-доверительный-интервал-1"><i class="fa fa-check"></i><b>6.2</b> Байесовский доверительный интервал</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="коэффициент-байеса.html"><a href="коэффициент-байеса.html"><i class="fa fa-check"></i><b>7</b> Коэффициент Байеса</a>
<ul>
<li class="chapter" data-level="7.1" data-path="коэффициент-байеса.html"><a href="коэффициент-байеса.html#коэффициент-байеса-1"><i class="fa fa-check"></i><b>7.1</b> Коэффициент Байеса</a></li>
<li class="chapter" data-level="7.2" data-path="коэффициент-байеса.html"><a href="коэффициент-байеса.html#формула-байеса-опять"><i class="fa fa-check"></i><b>7.2</b> Формула Байеса опять</a></li>
<li class="chapter" data-level="7.3" data-path="коэффициент-байеса.html"><a href="коэффициент-байеса.html#биномиальный-вариант"><i class="fa fa-check"></i><b>7.3</b> Биномиальный вариант</a></li>
<li class="chapter" data-level="7.4" data-path="коэффициент-байеса.html"><a href="коэффициент-байеса.html#интерпретация-коэффициента-байеса"><i class="fa fa-check"></i><b>7.4</b> <span>Интерпретация коэффициента Байеса</span></a></li>
<li class="chapter" data-level="7.5" data-path="коэффициент-байеса.html"><a href="коэффициент-байеса.html#дискретный-вариант"><i class="fa fa-check"></i><b>7.5</b> Дискретный вариант</a></li>
<li class="chapter" data-level="7.6" data-path="коэффициент-байеса.html"><a href="коэффициент-байеса.html#несколько-точечных-моделей"><i class="fa fa-check"></i><b>7.6</b> Несколько точечных моделей</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="ссылки-на-литературу.html"><a href="ссылки-на-литературу.html"><i class="fa fa-check"></i>Ссылки на литературу</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Анализ данных для лингвистов</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="коэффициент-байеса" class="section level1" number="7">
<h1><span class="header-section-number">7</span> Коэффициент Байеса</h1>
<div id="коэффициент-байеса-1" class="section level2" number="7.1">
<h2><span class="header-section-number">7.1</span> Коэффициент Байеса</h2>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb76-1"><a href="коэффициент-байеса.html#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span></code></pre></div>
<p>В прошлой лекции мы обсуждали значения правдоподобия. Важно понимать, что само по себе значение правдоподобия бессмысленно, оно важно для сравнения со значениями правдоподобия разных моделей. Представим, что мы пытаемся выбрать между двумя моделями:</p>
<ul>
<li><span class="math inline">\(H_1 = X \sim \ln\mathcal{N}(\mu = 3,\, \sigma^{2}= 0.37)\)</span></li>
<li><span class="math inline">\(H_2 = X \sim \ln\mathcal{N}(\mu = 3.5,\, \sigma^{2}= 0.25)\)</span></li>
</ul>
<p><img src="da4l_files/figure-html/unnamed-chunk-103-1.png" width="672" /></p>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="коэффициент-байеса.html#cb77-1" aria-hidden="true" tabindex="-1"></a>L1 <span class="ot">&lt;-</span> <span class="fu">dlnorm</span>(<span class="dv">33</span>, <span class="dv">3</span>, <span class="fl">0.37</span>)<span class="sc">*</span><span class="fu">dlnorm</span>(<span class="dv">26</span>, <span class="dv">3</span>, <span class="fl">0.37</span>)</span>
<span id="cb77-2"><a href="коэффициент-байеса.html#cb77-2" aria-hidden="true" tabindex="-1"></a>L2 <span class="ot">&lt;-</span> <span class="fu">dlnorm</span>(<span class="dv">33</span>, <span class="fl">3.5</span>, <span class="fl">0.25</span>)<span class="sc">*</span><span class="fu">dlnorm</span>(<span class="dv">26</span>, <span class="fl">3.5</span>, <span class="fl">0.25</span>)</span>
<span id="cb77-3"><a href="коэффициент-байеса.html#cb77-3" aria-hidden="true" tabindex="-1"></a>L2<span class="sc">/</span>L1</span></code></pre></div>
<pre><code>[1] 4.303835</code></pre>
<p>Как мы видим, на основании наших (фейковых) данных <span class="math inline">\(H_2\)</span> в 4 раза более вероятнее, чем <span class="math inline">\(H_1\)</span>. Надо отметить, что не все тепло относятся к сравнению моделей (см. <a href="https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.44.6443">Gelman, Rubin 1994</a>).</p>
</div>
<div id="формула-байеса-опять" class="section level2" number="7.2">
<h2><span class="header-section-number">7.2</span> Формула Байеса опять</h2>
<p>Представим себе, что у нас есть <span class="math inline">\(k\)</span> гипотез <span class="math inline">\(M\)</span>. Тогда формула Байеса может выглядеть вот так:</p>
<p><span class="math display">\[P(θ|Data, M_k) = \frac{P(Data|θ, M_k) \times  P(θ| M_k) }{P(Data|M_k)}\]</span></p>
<p>Коэффициент Байеса определяют как соотношение предельных правдоподобий (<span class="math inline">\(P(Data, M_k)\)</span>) моделей (в принципе их может быть больше двух):</p>
<p><span class="math display">\[
BF_{12} = \frac{P(Data | M_1 )}{P(Data | M_2)}
\]</span></p>
<p>Вычислять предельные правдоподобия порой достаточно сложно, так что иногда используют численную аппроксимацию.</p>
</div>
<div id="биномиальный-вариант" class="section level2" number="7.3">
<h2><span class="header-section-number">7.3</span> Биномиальный вариант</h2>
<p>Рассмотрим пример эксперимента Бернулли:</p>
<ul>
<li>мы посчитали количество букв “а” в рассказе А. П. Чехова и получили 58 букв из рассказа длинной 699 букв (пробелы и латинские буквы выкинуты);</li>
<li>представим, что у нас есть две модели, соогласно одной мы ожидаем долю 0.08, а согласно другой 0.085.</li>
</ul>
<p>Мы помним, что эксперимент Бернулли описывается биномиальным распределением:</p>
<p><span class="math display">\[P(k | n, p) = \frac{n!}{k!(n-k)!} \times p^k \times (1-p)^{n-k} =  {n \choose k} \times p^k \times (1-p)^{n-k}\]</span></p>
<p>Так что в случае наших моделей будет:</p>
<p><span class="math display">\[P(Data | M_1) = {n \choose k} \times p^k \times (1-p)^{n-k} = {699 \choose 58} \times 0.08^{58} \times (1-0.08)^{699-58} = 0.0523985\]</span></p>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="коэффициент-байеса.html#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dbinom</span>(<span class="dv">58</span>, <span class="dv">699</span>, <span class="at">prob =</span> <span class="fl">0.08</span>)</span></code></pre></div>
<pre><code>[1] 0.0523985</code></pre>
<p><span class="math display">\[P(Data | M_2) = {n \choose k} \times p^k \times (1-p)^{n-k} = {699 \choose 58} \times 0.085^{58} \times (1-0.085)^{699-58} = 0.04402509\]</span></p>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="коэффициент-байеса.html#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dbinom</span>(<span class="dv">58</span>, <span class="dv">699</span>, <span class="at">prob =</span> <span class="fl">0.09</span>)</span></code></pre></div>
<pre><code>[1] 0.04402509</code></pre>
<p>Тогда коэфициент Байеса будет</p>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="коэффициент-байеса.html#cb83-1" aria-hidden="true" tabindex="-1"></a>BF_12 <span class="ot">=</span> <span class="fu">dbinom</span>(<span class="dv">58</span>, <span class="dv">699</span>, <span class="at">prob =</span> <span class="fl">0.08</span>)<span class="sc">/</span><span class="fu">dbinom</span>(<span class="dv">58</span>, <span class="dv">699</span>, <span class="at">prob =</span> <span class="fl">0.09</span>)</span>
<span id="cb83-2"><a href="коэффициент-байеса.html#cb83-2" aria-hidden="true" tabindex="-1"></a>BF_12</span></code></pre></div>
<pre><code>[1] 1.190196</code></pre>
<p><img src="da4l_files/figure-html/unnamed-chunk-108-1.png" width="672" /></p>
</div>
<div id="интерпретация-коэффициента-байеса" class="section level2" number="7.4">
<h2><span class="header-section-number">7.4</span> <a href="https://en.wikipedia.org/wiki/Bayes_factor#Interpretation">Интерпретация коэффициента Байеса</a></h2>
</div>
<div id="дискретный-вариант" class="section level2" number="7.5">
<h2><span class="header-section-number">7.5</span> Дискретный вариант</h2>
<p>Для примера обратися снова к датасету, который содержит спамерские и обычные смс-сообщения, выложенный UCI Machine Learning <a href="https://www.kaggle.com/uciml/sms-spam-collection-dataset">на kaggle</a> и при помощи пакета <code>udpipe</code> токенизировал и определил часть речи:</p>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="коэффициент-байеса.html#cb85-1" aria-hidden="true" tabindex="-1"></a>sms_pos <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&quot;https://raw.githubusercontent.com/agricolamz/2021_da4l/master/data/spam_sms_pos.csv&quot;</span>)</span>
<span id="cb85-2"><a href="коэффициент-байеса.html#cb85-2" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(sms_pos)</span></code></pre></div>
<pre><code>Rows: 34
Columns: 3
$ type &lt;chr&gt; &quot;ham&quot;, &quot;ham&quot;, &quot;ham&quot;, &quot;ham&quot;, &quot;ham&quot;, &quot;ham&quot;, &quot;ham&quot;, &quot;ham&quot;, &quot;ham&quot;, &quot;…
$ upos &lt;chr&gt; &quot;ADJ&quot;, &quot;ADP&quot;, &quot;ADV&quot;, &quot;AUX&quot;, &quot;CCONJ&quot;, &quot;DET&quot;, &quot;INTJ&quot;, &quot;NOUN&quot;, &quot;NUM…
$ n    &lt;dbl&gt; 4329, 5004, 5832, 5707, 1607, 3493, 1676, 12842, 1293, 2424, 114…</code></pre>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb87-1"><a href="коэффициент-байеса.html#cb87-1" aria-hidden="true" tabindex="-1"></a>sms_pos <span class="sc">%&gt;%</span> </span>
<span id="cb87-2"><a href="коэффициент-байеса.html#cb87-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(type) <span class="sc">%&gt;%</span> </span>
<span id="cb87-3"><a href="коэффициент-байеса.html#cb87-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">ratio =</span> n<span class="sc">/</span><span class="fu">sum</span>(n),</span>
<span id="cb87-4"><a href="коэффициент-байеса.html#cb87-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">upos =</span> <span class="fu">fct_reorder</span>(upos, n, mean, <span class="at">.desc =</span> <span class="cn">TRUE</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb87-5"><a href="коэффициент-байеса.html#cb87-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(type, ratio))<span class="sc">+</span></span>
<span id="cb87-6"><a href="коэффициент-байеса.html#cb87-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_col</span>()<span class="sc">+</span></span>
<span id="cb87-7"><a href="коэффициент-байеса.html#cb87-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_label</span>(<span class="fu">aes</span>(<span class="at">label =</span> <span class="fu">round</span>(ratio, <span class="dv">3</span>)), <span class="at">position =</span> <span class="fu">position_stack</span>(<span class="at">vjust =</span> <span class="fl">0.5</span>))<span class="sc">+</span></span>
<span id="cb87-8"><a href="коэффициент-байеса.html#cb87-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span>upos, <span class="at">scales =</span> <span class="st">&quot;free_y&quot;</span>)</span></code></pre></div>
<p><img src="da4l_files/figure-html/unnamed-chunk-109-1.png" width="864" /></p>
<p>Давайте полученные доли считать нашей моделью: сумма всех чисел внутри каждого типа (<code>ham</code>/<code>spam</code>) дает в сумме 1. Мы получили новое сообщение:</p>
<blockquote>
<p>Call FREEPHONE 0800 542 0825 now!</p>
</blockquote>
<p>Модель <code>udpipe</code> разобрала его следующим образом:</p>
<blockquote>
<p>VERB NUM NUM NUM NUM ADV PUNCT</p>
</blockquote>
<p><span class="math display">\[L(VERB,\ NUM|ham) = 0.135 \times 0.016 = 0.00216\]</span></p>
<p><span class="math display">\[L(VERB,\ NUM|spam) = 0.096 \times 0.117 = 0.011232\]</span></p>
<p><span class="math display">\[BF_{ham\ spam} = \frac{L(VERB,\ NUM|ham)}{L(VERB,\ NUM|spam)} = \frac{0.00216}{0.011232} = 0.1923077\]</span></p>
</div>
<div id="несколько-точечных-моделей" class="section level2" number="7.6">
<h2><span class="header-section-number">7.6</span> Несколько точечных моделей</h2>
<p>До сих пор мы рассматривали одну точечную модель, сравнивая доли 0.08 и 0.085.</p>
<ul>
<li>Мы посчитали количество букв “а” в рассказе А. П. Чехова и получили 58 букв из рассказа длинной 699 букв (пробелы и латинские буквы выкинуты);</li>
<li>представим, что у нас есть две модели, соогласно одной мы ожидаем долю 0.08, а вторая модель состоит из 7 равновероятных моделей: 0.60 0.65 0.70 0.75 0.80 0.85 0.90.</li>
</ul>
<p>Функцию правдоподобия для первой модели мы уже считали:</p>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb88-1"><a href="коэффициент-байеса.html#cb88-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dbinom</span>(<span class="dv">58</span>, <span class="dv">699</span>, <span class="at">prob =</span> <span class="fl">0.08</span>)</span></code></pre></div>
<pre><code>[1] 0.0523985</code></pre>
<p>Функция правдоподобия второй модели – это среднее функций правдоподобия всех входящих моделей:</p>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb90-1"><a href="коэффициент-байеса.html#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(<span class="fu">dbinom</span>(<span class="dv">58</span>, <span class="dv">699</span>, <span class="at">prob =</span> <span class="fu">seq</span>(<span class="fl">0.08</span>, <span class="fl">0.085</span>, <span class="fl">0.001</span>)))</span></code></pre></div>
<pre><code>[1] 0.05383749</code></pre>
<p>Байес фактор:</p>
<div class="sourceCode" id="cb92"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb92-1"><a href="коэффициент-байеса.html#cb92-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(<span class="fu">dbinom</span>(<span class="dv">58</span>, <span class="dv">699</span>, <span class="at">prob =</span> <span class="fu">seq</span>(<span class="fl">0.08</span>, <span class="fl">0.085</span>, <span class="fl">0.001</span>)))<span class="sc">/</span><span class="fu">dbinom</span>(<span class="dv">58</span>, <span class="dv">699</span>, <span class="at">prob =</span> <span class="fl">0.08</span>)</span></code></pre></div>
<pre><code>[1] 1.027462</code></pre>
<p>Как видим, наша распределенная модель немного предпочтительнее, чем точечная.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="байесовский-доверительный-интервал.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="ссылки-на-литературу.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/agricolamz/2021_da4l/edit/master/06_Bayes_factor.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["da4l.pdf"],
"toc": {
"collapse": "section"
},
"self_contained": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
